{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from linearization.analyzer import SAELinearizer\n",
    "from linearization.visualization import visualize_topk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPANSION_FACTOR = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gelu-2l into HookedTransformer\n",
      "Moving model to device:  cuda\n",
      "Model device: cuda:0\n",
      "Tokens shape: torch.Size([125337, 128]), dtype: torch.int64, device: cuda:0\n",
      "Loading ../scripts/checkpoints/32x_gelu_2l/layer0/seed42_ln2_normalized/final_sparse_autoencoder_gelu-2l_blocks.0.ln2.hook_normalized_16384.pt from disk\n",
      "Encoder device: cuda:0\n",
      "Loading ../scripts/checkpoints/32x_gelu_2l/layer0/seed42_mlp_out/final_sparse_autoencoder_gelu-2l_blocks.0.hook_mlp_out_16384.pt from disk\n",
      "Encoder device: cuda:0\n",
      "Loading ../scripts/checkpoints/32x_gelu_2l/layer0/seed42_transcoder/final_sparse_autoencoder_gelu-2l_blocks.0.ln2.hook_normalized_16384.pt from disk\n",
      "Encoder device: cuda:0\n",
      "Loading ../scripts/checkpoints/32x_gelu_2l/layer1/seed42_ln2_normalized/final_sparse_autoencoder_gelu-2l_blocks.1.ln2.hook_normalized_16384.pt from disk\n",
      "Encoder device: cuda:0\n",
      "Loading ../scripts/checkpoints/32x_gelu_2l/layer1/seed42_mlp_out/final_sparse_autoencoder_gelu-2l_blocks.1.hook_mlp_out_16384.pt from disk\n",
      "Encoder device: cuda:0\n",
      "Loading ../scripts/checkpoints/32x_gelu_2l/layer1/seed42_transcoder/final_sparse_autoencoder_gelu-2l_blocks.1.ln2.hook_normalized_16384.pt from disk\n",
      "Encoder device: cuda:0\n",
      "Loading ../scripts/checkpoints/32x_gelu_2l/layer0/seed43_ln2_normalized/final_sparse_autoencoder_gelu-2l_blocks.0.ln2.hook_normalized_16384.pt from disk\n",
      "Encoder device: cuda:0\n",
      "Loading ../scripts/checkpoints/32x_gelu_2l/layer0/seed43_mlp_out/final_sparse_autoencoder_gelu-2l_blocks.0.hook_mlp_out_16384.pt from disk\n",
      "Encoder device: cuda:0\n",
      "Loading ../scripts/checkpoints/32x_gelu_2l/layer0/seed43_transcoder/final_sparse_autoencoder_gelu-2l_blocks.0.ln2.hook_normalized_16384.pt from disk\n",
      "Encoder device: cuda:0\n",
      "Loading ../scripts/checkpoints/32x_gelu_2l/layer1/seed43_ln2_normalized/final_sparse_autoencoder_gelu-2l_blocks.1.ln2.hook_normalized_16384.pt from disk\n",
      "Encoder device: cuda:0\n",
      "Loading ../scripts/checkpoints/32x_gelu_2l/layer1/seed43_mlp_out/final_sparse_autoencoder_gelu-2l_blocks.1.hook_mlp_out_16384.pt from disk\n",
      "Encoder device: cuda:0\n",
      "Loading ../scripts/checkpoints/32x_gelu_2l/layer1/seed43_transcoder/final_sparse_autoencoder_gelu-2l_blocks.1.ln2.hook_normalized_16384.pt from disk\n",
      "Encoder device: cuda:0\n",
      "dict_keys(['../scripts/checkpoints/32x_gelu_2l/layer0/seed42_ln2_normalized/final_sparse_autoencoder_gelu-2l_blocks.0.ln2.hook_normalized_16384.pt', '../scripts/checkpoints/32x_gelu_2l/layer0/seed42_mlp_out/final_sparse_autoencoder_gelu-2l_blocks.0.hook_mlp_out_16384.pt', '../scripts/checkpoints/32x_gelu_2l/layer0/seed42_transcoder/final_sparse_autoencoder_gelu-2l_blocks.0.ln2.hook_normalized_16384.pt', '../scripts/checkpoints/32x_gelu_2l/layer1/seed42_ln2_normalized/final_sparse_autoencoder_gelu-2l_blocks.1.ln2.hook_normalized_16384.pt', '../scripts/checkpoints/32x_gelu_2l/layer1/seed42_mlp_out/final_sparse_autoencoder_gelu-2l_blocks.1.hook_mlp_out_16384.pt', '../scripts/checkpoints/32x_gelu_2l/layer1/seed42_transcoder/final_sparse_autoencoder_gelu-2l_blocks.1.ln2.hook_normalized_16384.pt', '../scripts/checkpoints/32x_gelu_2l/layer0/seed43_ln2_normalized/final_sparse_autoencoder_gelu-2l_blocks.0.ln2.hook_normalized_16384.pt', '../scripts/checkpoints/32x_gelu_2l/layer0/seed43_mlp_out/final_sparse_autoencoder_gelu-2l_blocks.0.hook_mlp_out_16384.pt', '../scripts/checkpoints/32x_gelu_2l/layer0/seed43_transcoder/final_sparse_autoencoder_gelu-2l_blocks.0.ln2.hook_normalized_16384.pt', '../scripts/checkpoints/32x_gelu_2l/layer1/seed43_ln2_normalized/final_sparse_autoencoder_gelu-2l_blocks.1.ln2.hook_normalized_16384.pt', '../scripts/checkpoints/32x_gelu_2l/layer1/seed43_mlp_out/final_sparse_autoencoder_gelu-2l_blocks.1.hook_mlp_out_16384.pt', '../scripts/checkpoints/32x_gelu_2l/layer1/seed43_transcoder/final_sparse_autoencoder_gelu-2l_blocks.1.ln2.hook_normalized_16384.pt'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 28.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num dead 6.103515625e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 25.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num dead 0.02044677734375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 27.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num dead 0.04638671875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 28.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num dead 0.00042724609375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 29.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num dead 0.38861083984375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 27.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num dead 0.04638671875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 27.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num dead 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 31.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num dead 0.0206298828125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 21.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num dead 0.0155029296875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 20.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num dead 0.0001220703125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 24.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num dead 0.38287353515625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 23.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num dead 0.0487060546875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:10<00:00,  7.04s/it]\n",
      "100%|██████████| 10/10 [03:54<00:00, 23.46s/it]\n",
      "100%|██████████| 10/10 [01:01<00:00,  6.16s/it]\n",
      "100%|██████████| 10/10 [01:13<00:00,  7.34s/it]\n",
      "100%|██████████| 10/10 [00:53<00:00,  5.30s/it]\n",
      "100%|██████████| 10/10 [01:05<00:00,  6.56s/it]\n",
      "100%|██████████| 10/10 [01:06<00:00,  6.64s/it]\n",
      "100%|██████████| 10/10 [02:26<00:00, 14.61s/it]\n",
      "100%|██████████| 10/10 [01:04<00:00,  6.48s/it]\n",
      "100%|██████████| 10/10 [01:13<00:00,  7.35s/it]\n",
      "100%|██████████| 10/10 [00:51<00:00,  5.18s/it]\n",
      "100%|██████████| 10/10 [01:06<00:00,  6.68s/it]\n"
     ]
    }
   ],
   "source": [
    "OVERRIDE = True\n",
    "\n",
    "path = f\"../data/pickled_linearizers/gelu_2l_{EXPANSION_FACTOR}.pkl\"\n",
    "\n",
    "# # Get SAE names automatically\n",
    "# prefix = \"../scripts/checkpoints/64x_resid_mid/\"\n",
    "# sae_names = []\n",
    "# for i in range(12):\n",
    "#     with os.scandir(prefix + f\"layer{i}\") as it:\n",
    "#         for entry in it:\n",
    "#             if entry.name.startswith(\"final\") and not entry.name.endswith(\"sparsity.pt\") and entry.is_file():\n",
    "#                 sae_names.append(entry.path)\n",
    "# print(\"SAE names:\", sae_names)\n",
    "\n",
    "# sae_names = [\n",
    "#     f\"../scripts/checkpoints/{EXPANSION_FACTOR}x_gelu_2l/layer0/seed42_ln2_normalized/final_sparse_autoencoder_gelu-2l_blocks.0.ln2.hook_normalized_16384.pt\",\n",
    "#     f\"../scripts/checkpoints/{EXPANSION_FACTOR}x_gelu_2l/layer0/seed42_mlp_out/final_sparse_autoencoder_gelu-2l_blocks.0.hook_mlp_out_16384.pt\",\n",
    "#     f\"../scripts/checkpoints/{EXPANSION_FACTOR}x_gelu_2l/layer0/seed42_transcoder/final_sparse_autoencoder_gelu-2l_blocks.0.ln2.hook_normalized_16384.pt\",\n",
    "#     f\"../scripts/checkpoints/{EXPANSION_FACTOR}x_gelu_2l/layer1/seed42_ln2_normalized/final_sparse_autoencoder_gelu-2l_blocks.1.ln2.hook_normalized_16384.pt\",\n",
    "#     f\"../scripts/checkpoints/{EXPANSION_FACTOR}x_gelu_2l/layer1/seed42_mlp_out/final_sparse_autoencoder_gelu-2l_blocks.1.hook_mlp_out_16384.pt\",\n",
    "#     f\"../scripts/checkpoints/{EXPANSION_FACTOR}x_gelu_2l/layer1/seed42_transcoder/final_sparse_autoencoder_gelu-2l_blocks.1.ln2.hook_normalized_16384.pt\",\n",
    "#     f\"../scripts/checkpoints/{EXPANSION_FACTOR}x_gelu_2l/layer0/seed43_ln2_normalized/final_sparse_autoencoder_gelu-2l_blocks.0.ln2.hook_normalized_16384.pt\",\n",
    "#     f\"../scripts/checkpoints/{EXPANSION_FACTOR}x_gelu_2l/layer0/seed43_mlp_out/final_sparse_autoencoder_gelu-2l_blocks.0.hook_mlp_out_16384.pt\",\n",
    "#     f\"../scripts/checkpoints/{EXPANSION_FACTOR}x_gelu_2l/layer0/seed43_transcoder/final_sparse_autoencoder_gelu-2l_blocks.0.ln2.hook_normalized_16384.pt\",\n",
    "#     f\"../scripts/checkpoints/{EXPANSION_FACTOR}x_gelu_2l/layer1/seed43_ln2_normalized/final_sparse_autoencoder_gelu-2l_blocks.1.ln2.hook_normalized_16384.pt\",\n",
    "#     f\"../scripts/checkpoints/{EXPANSION_FACTOR}x_gelu_2l/layer1/seed43_mlp_out/final_sparse_autoencoder_gelu-2l_blocks.1.hook_mlp_out_16384.pt\",\n",
    "#     f\"../scripts/checkpoints/{EXPANSION_FACTOR}x_gelu_2l/layer1/seed43_transcoder/final_sparse_autoencoder_gelu-2l_blocks.1.ln2.hook_normalized_16384.pt\",\n",
    "# ]\n",
    "\n",
    "# Automated SAE name generation\n",
    "seeds = [42, 43]\n",
    "layers = [0, 1]\n",
    "names1 = [\"ln2_normalized\", \"mlp_out\", \"transcoder\"]\n",
    "names2 = [\"ln2.hook_normalized\", \"hook_mlp_out\", \"ln2.hook_normalized\"]\n",
    "\n",
    "sae_names = []\n",
    "for seed in seeds:\n",
    "    for layer in layers:\n",
    "        for name1, name2 in zip(names1, names2):\n",
    "            sae_names.append(\n",
    "                f\"../scripts/checkpoints/{EXPANSION_FACTOR}x_gelu_2l/layer{layer}/seed{seed}_{name1}/final_sparse_autoencoder_gelu-2l_blocks.{layer}.{name2}_16384.pt\"\n",
    "            )\n",
    "\n",
    "if os.path.exists(path) and not OVERRIDE:\n",
    "    lin = pickle.load(open(path, \"rb\"))\n",
    "else:\n",
    "    lin = SAELinearizer(\n",
    "        model_name=\"gelu-2l\",\n",
    "        sae_names=sae_names,\n",
    "        layers=[0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1],\n",
    "        dataset_name=\"NeelNanda/pile-10k\",\n",
    "        act_name=\"normalized\",\n",
    "        num_batches=10,\n",
    "        half_precision=False,\n",
    "        # transcoder=True,\n",
    "        # use_gpt=True,\n",
    "        # dict_mult=64,\n",
    "        # hook_point=\"resid_mid\",\n",
    "        run_analysis=True,\n",
    "    )\n",
    "    with open(path, \"wb\") as f:\n",
    "        pickle.dump(lin, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "# 5 features, uniformly sampled by frequency, seed 42 layer 0:\n",
    "\n",
    "sae_name = \"../scripts/checkpoints/32x_gelu_2l/layer0/seed42_transcoder/final_sparse_autoencoder_gelu-2l_blocks.0.ln2.hook_normalized_16384.pt\"\n",
    "freqs = lin.frequencies[sae_name]\n",
    "\n",
    "my_sample = np.argsort(freqs.cpu().numpy())[::-1][::len(freqs) // 5]\n",
    "print(len(my_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 4/25 [00:00<00:01, 14.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/phil/miniconda3/envs/mats/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_644995/3163856484.py\", line 1, in <module>\n",
      "    lin.set_feature(my_sample[0], sae_name)\n",
      "  File \"/home/phil/mlp_linearization/src/linearization/analyzer.py\", line 110, in set_feature\n",
      "    self.top_examples = top_activating_examples(**self._kw2, num_batches=num_batches)\n",
      "  File \"/home/phil/mlp_linearization/src/linearization/analyses/feature.py\", line 84, in top_activating_examples\n",
      "    activations, tokens = _get_sample(model, sae, data, feature_idx, layer, act_name, num_batches)\n",
      "  File \"/home/phil/mlp_linearization/src/linearization/analyses/feature.py\", line 25, in _get_sample\n",
      "    _, cache = model.run_with_cache(tokens, names_filter=get_act_name(act_name, layer, layer_name))\n",
      "  File \"/home/phil/miniconda3/envs/mats/lib/python3.10/site-packages/transformer_lens/HookedTransformer.py\", line 634, in run_with_cache\n",
      "    out, cache_dict = super().run_with_cache(\n",
      "  File \"/home/phil/miniconda3/envs/mats/lib/python3.10/site-packages/transformer_lens/hook_points.py\", line 467, in run_with_cache\n",
      "    model_out = self(*model_args, **model_kwargs)\n",
      "  File \"/home/phil/miniconda3/envs/mats/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/phil/miniconda3/envs/mats/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/phil/miniconda3/envs/mats/lib/python3.10/site-packages/transformer_lens/HookedTransformer.py\", line 575, in forward\n",
      "    logits = self.unembed(residual)  # [batch, pos, d_vocab]\n",
      "  File \"/home/phil/miniconda3/envs/mats/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/phil/miniconda3/envs/mats/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/phil/miniconda3/envs/mats/lib/python3.10/site-packages/transformer_lens/components.py\", line 67, in forward\n",
      "    einsum(\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.47 GiB. GPU 0 has a total capacty of 23.65 GiB of which 680.25 MiB is free. Process 1452144 has 12.94 GiB memory in use. Process 2936519 has 10.04 GiB memory in use. Of the allocated memory 7.56 GiB is allocated by PyTorch, and 2.04 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/phil/miniconda3/envs/mats/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2120, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/home/phil/miniconda3/envs/mats/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/home/phil/miniconda3/envs/mats/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/home/phil/miniconda3/envs/mats/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/home/phil/miniconda3/envs/mats/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"/home/phil/miniconda3/envs/mats/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"/home/phil/miniconda3/envs/mats/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "  File \"/home/phil/miniconda3/envs/mats/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/phil/miniconda3/envs/mats/lib/python3.10/site-packages/stack_data/core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/home/phil/miniconda3/envs/mats/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/phil/miniconda3/envs/mats/lib/python3.10/site-packages/stack_data/core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/home/phil/miniconda3/envs/mats/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/phil/miniconda3/envs/mats/lib/python3.10/site-packages/stack_data/core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "  File \"/home/phil/miniconda3/envs/mats/lib/python3.10/site-packages/executing/executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "lin.set_feature(my_sample[0], sae_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mats",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
