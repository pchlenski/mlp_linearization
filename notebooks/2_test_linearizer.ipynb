{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test linearizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from linearization.analyzer import SAELinearizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GELU-1L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic setting methods work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gelu-1l into HookedTransformer\n",
      "Moving model to device:  cuda\n",
      "Changing model dtype to torch.float16\n",
      "Model device: cuda:0\n",
      "Tokens shape: torch.Size([215402, 128]), dtype: torch.int64, device: cuda:0\n",
      "Loading run1 from HuggingFace at 25\n",
      "{'batch_size': 4096,\n",
      " 'beta1': 0.9,\n",
      " 'beta2': 0.99,\n",
      " 'buffer_batches': 12288,\n",
      " 'buffer_mult': 384,\n",
      " 'buffer_size': 1572864,\n",
      " 'd_mlp': 2048,\n",
      " 'dict_mult': 8,\n",
      " 'enc_dtype': 'fp32',\n",
      " 'l1_coeff': 0.0003,\n",
      " 'lr': 0.0001,\n",
      " 'model_batch_size': 512,\n",
      " 'num_tokens': 2000000000,\n",
      " 'seed': 52,\n",
      " 'seq_len': 128}\n",
      "Encoder device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:01<00:00, 24.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num dead 0.000244140625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.43s/it]\n"
     ]
    }
   ],
   "source": [
    "lin = SAELinearizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 31.27it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 30.92it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 28.82it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 34.04it/s]\n"
     ]
    }
   ],
   "source": [
    "lin.set_feature(10996, \"run1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9])\n",
      "Token:  the\n"
     ]
    }
   ],
   "source": [
    "lin.set_example(\"The quick brown fox jumps over the lazy dog\", 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x2048 and 512x2048)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[84], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mlin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mattention\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mlp_linearization/src/linearization/analyzer.py:189\u001b[0m, in \u001b[0;36mSAELinearizer.set_path\u001b[0;34m(self, path, run_analysis)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_analysis:\n\u001b[1;32m    187\u001b[0m     torch\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseed)\n\u001b[0;32m--> 189\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_vectors \u001b[38;5;241m=\u001b[39m \u001b[43mfeature_vectors\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_kw4\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mlp_linearization/src/linearization/analyses/path.py:53\u001b[0m, in \u001b[0;36mfeature_vectors\u001b[0;34m(model, example, token_idx, start_vector, path, mlp_out, act_name, layer, **absorb)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Always do direct path\u001b[39;00m\n\u001b[1;32m     51\u001b[0m x \u001b[38;5;241m=\u001b[39m cache[utils\u001b[38;5;241m.\u001b[39mget_act_name(act_name, layer)][\u001b[38;5;241m0\u001b[39m, token_idx][\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, :]\n\u001b[1;32m     52\u001b[0m feature_mid \u001b[38;5;241m=\u001b[39m get_tangent_plane_at_point(\n\u001b[0;32m---> 53\u001b[0m     x, \u001b[43mmy_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_ln\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m, start_vector\n\u001b[1;32m     54\u001b[0m )[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     55\u001b[0m vecs \u001b[38;5;241m=\u001b[39m [feature_mid]\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Also anything else in the path\u001b[39;00m\n",
      "File \u001b[0;32m~/mlp_linearization/src/linearization/layers.py:15\u001b[0m, in \u001b[0;36mln2_mlp_until_post\u001b[0;34m(x, ln, mlp, use_ln)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_ln:\n\u001b[1;32m     14\u001b[0m     x \u001b[38;5;241m=\u001b[39m ln(x)\n\u001b[0;32m---> 15\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmlp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mW_in\u001b[49m \u001b[38;5;241m+\u001b[39m mlp\u001b[38;5;241m.\u001b[39mb_in\n\u001b[1;32m     16\u001b[0m x \u001b[38;5;241m=\u001b[39m mlp\u001b[38;5;241m.\u001b[39mact_fn(x)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x2048 and 512x2048)"
     ]
    }
   ],
   "source": [
    "lin.set_path([(\"attention\", 0, 3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'post'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin.act_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8416</th>\n",
       "      <td>Ġeditions</td>\n",
       "      <td>1.202148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13327</th>\n",
       "      <td>[,</td>\n",
       "      <td>1.005859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24753</th>\n",
       "      <td>rectomy</td>\n",
       "      <td>1.003906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41692</th>\n",
       "      <td>rapeut</td>\n",
       "      <td>0.985352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7830</th>\n",
       "      <td>opathology</td>\n",
       "      <td>0.957520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9613</th>\n",
       "      <td>capt</td>\n",
       "      <td>0.933594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26389</th>\n",
       "      <td>Ġproperties</td>\n",
       "      <td>0.931641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33886</th>\n",
       "      <td>remia</td>\n",
       "      <td>0.886230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29596</th>\n",
       "      <td>Ġcontacted</td>\n",
       "      <td>0.881836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48081</th>\n",
       "      <td>ikes</td>\n",
       "      <td>0.880371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0         1\n",
       "8416     Ġeditions  1.202148\n",
       "13327           [,  1.005859\n",
       "24753      rectomy  1.003906\n",
       "41692       rapeut  0.985352\n",
       "7830    opathology  0.957520\n",
       "9613          capt  0.933594\n",
       "26389  Ġproperties  0.931641\n",
       "33886        remia  0.886230\n",
       "29596   Ġcontacted  0.881836\n",
       "48081         ikes  0.880371"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydf = direct_path_deembed_df = pd.DataFrame(\n",
    "    zip(lin.model.tokenizer.vocab.keys(), (lin.model.W_E @ lin.range_normal).detach().cpu().numpy())\n",
    ")\n",
    "mydf.sort_values(by=1, ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match the old notebooks:\n",
    "Link: [SAE Feature tracing 2](https://colab.research.google.com/drive/1FFq5OAHIrK1i5BovJ3oMFQH8gUMm89Wo?usp=drive_link#scrollTo=RTZud0Rk7qg9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 26.57it/s]\n",
      "100%|██████████| 50/50 [00:01<00:00, 26.12it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 25.00it/s]\n",
      "100%|██████████| 50/50 [00:01<00:00, 25.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token:  is\n"
     ]
    }
   ],
   "source": [
    "lin.set_feature(4958, \"run1\", num_batches=50)  # Due to memory constraints, we only use 50 batches\n",
    "lin.set_example(7030, 98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|BOS|> when Holland and Britain respectively sought to reconfigure South Africa in strategies that \n"
     ]
    }
   ],
   "source": [
    "# Confirm examples match - should be \"<|BOS|> when Holland and Britain respectively sought...\"\n",
    "print(lin.model.tokenizer.decode(lin.example)[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", which is sometimes seen as a modern phenomenon, is nothing new. In 1858,\n",
      " its scenic vistas, Colorado’s spiritual landscape is largely barren. We have found many people\n",
      " because they know their time is short. The earth is not becoming less spiritual. We are headed towards\n",
      " to express their masculinity through bodily perfection, which is sometimes seen as a modern phenomenon, is nothing\n",
      "s deployment of border troops as “political theater” is borne out by news accounts from final April.\n",
      " of nature. It is in its recognition that India is trying its best to include the paradigm\n",
      " from this slavery and His eternal judgment. Christians have been sent into the entire world to set people free\n",
      "ility. More importantly, the emotional demeanour is similar to the first song, we lack a\n",
      " correct. And just because the true nature of animals is something we don't want to think about,\n",
      " feel to Star Trek III. This hateful tone is a direct contrast with the rest of the Trek\n"
     ]
    }
   ],
   "source": [
    "# Top examples don't exactly match, due to shuffling of batches, but they show the same interpretation:\n",
    "\n",
    "for example, col in zip(lin.top_examples[\"examples\"], lin.top_examples[\"cols\"]):\n",
    "    print(lin.model.tokenizer.decode(example[col - 10 : col + 10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([13])\n",
      "Token:  is\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.6621, 0.0000]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
      "\n",
      "torch.Size([6])\n",
      "Token:  understand\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1541, 0.0000]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
      "\n",
      "Token:  is\n"
     ]
    }
   ],
   "source": [
    "# Feature scores for prompt 1\n",
    "prompt = \"When we think about God, we must understand that His love is\"\n",
    "lin.set_example(prompt, token_idx=13)\n",
    "print(lin.example_scores)\n",
    "print()\n",
    "\n",
    "# And for prompt 2\n",
    "prompt = \"What I don't understand is\"\n",
    "lin.set_example(prompt, token_idx=5)\n",
    "print(lin.example_scores)\n",
    "print()\n",
    "\n",
    "# Set example back\n",
    "lin.set_example(7030, 98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39089</th>\n",
       "      <td>.''</td>\n",
       "      <td>-0.261719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11214</th>\n",
       "      <td>scheduled</td>\n",
       "      <td>-0.256836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24420</th>\n",
       "      <td>)!</td>\n",
       "      <td>-0.231567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6607</th>\n",
       "      <td>calling</td>\n",
       "      <td>-0.231323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13663</th>\n",
       "      <td>authorized</td>\n",
       "      <td>-0.230957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16531</th>\n",
       "      <td>ARE</td>\n",
       "      <td>0.312988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1441</th>\n",
       "      <td>'re</td>\n",
       "      <td>0.349854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>was</td>\n",
       "      <td>0.357910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>are</td>\n",
       "      <td>0.418213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>is</td>\n",
       "      <td>0.471436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48262 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0         1\n",
       "39089          .'' -0.261719\n",
       "11214    scheduled -0.256836\n",
       "24420           )! -0.231567\n",
       "6607       calling -0.231323\n",
       "13663   authorized -0.230957\n",
       "...            ...       ...\n",
       "16531          ARE  0.312988\n",
       "1441           're  0.349854\n",
       "369            was  0.357910\n",
       "403            are  0.418213\n",
       "311             is  0.471436\n",
       "\n",
       "[48262 rows x 2 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check \"feature_mid\"\n",
    "\n",
    "# lin.set_path([])\n",
    "direct_path_deembed_df = pd.DataFrame(\n",
    "    zip(\n",
    "        lin.model.tokenizer.batch_decode(list(range(lin.model.tokenizer.vocab_size))),\n",
    "        (lin.model.W_E @ lin.feature_mid).detach().cpu().numpy(),\n",
    "    )\n",
    ")\n",
    "direct_path_deembed_df.sort_values(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GELU-2L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gelu-2l into HookedTransformer\n",
      "Moving model to device:  cuda\n",
      "Changing model dtype to torch.float16\n",
      "Model device: cuda:0\n",
      "Tokens shape: torch.Size([215402, 128]), dtype: torch.int64, device: cuda:0\n",
      "Loading l0 from HuggingFace at gelu-2l_L0_16384_mlp_out_51\n",
      "{'act_name': 'blocks.0.hook_mlp_out',\n",
      " 'act_size': 512,\n",
      " 'batch_size': 4096,\n",
      " 'beta1': 0.9,\n",
      " 'beta2': 0.99,\n",
      " 'buffer_batches': 12288,\n",
      " 'buffer_mult': 384,\n",
      " 'buffer_size': 1572864,\n",
      " 'd_mlp': 512,\n",
      " 'device': 'cuda:1',\n",
      " 'dict_mult': 32,\n",
      " 'dict_size': 16384,\n",
      " 'enc_dtype': 'fp32',\n",
      " 'l1_coeff': 0.0003,\n",
      " 'layer': 0,\n",
      " 'lr': 0.0001,\n",
      " 'model_batch_size': 512,\n",
      " 'model_name': 'gelu-2l',\n",
      " 'num_tokens': 2000000000,\n",
      " 'remove_rare_dir': False,\n",
      " 'seed': 51,\n",
      " 'seq_len': 128,\n",
      " 'site': 'mlp_out'}\n",
      "Encoder device: cuda:0\n",
      "Loading l1 from HuggingFace at gelu-2l_L1_16384_mlp_out_50\n",
      "{'act_name': 'blocks.1.hook_mlp_out',\n",
      " 'act_size': 512,\n",
      " 'batch_size': 4096,\n",
      " 'beta1': 0.9,\n",
      " 'beta2': 0.99,\n",
      " 'buffer_batches': 12288,\n",
      " 'buffer_mult': 384,\n",
      " 'buffer_size': 1572864,\n",
      " 'd_mlp': 512,\n",
      " 'device': 'cuda:0',\n",
      " 'dict_mult': 32,\n",
      " 'dict_size': 16384,\n",
      " 'enc_dtype': 'fp32',\n",
      " 'l1_coeff': 0.0003,\n",
      " 'layer': 1,\n",
      " 'lr': 0.0001,\n",
      " 'model_batch_size': 512,\n",
      " 'model_name': 'gelu-2l',\n",
      " 'num_tokens': 2000000000,\n",
      " 'remove_rare_dir': False,\n",
      " 'seed': 50,\n",
      " 'seq_len': 128,\n",
      " 'site': 'mlp_out'}\n",
      "Encoder device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 31.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num dead 0.1156005859375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 30.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num dead 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 21/25 [00:49<00:09,  2.36s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m lin \u001b[38;5;241m=\u001b[39m \u001b[43mSAELinearizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgelu-2l\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msae_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43ml0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43ml1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mact_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmlp_out\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mlp_linearization/src/linearization/analyzer.py:31\u001b[0m, in \u001b[0;36mSAELinearizer.__init__\u001b[0;34m(self, model_name, dataset_name, sae_names, layers, act_name, device, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m device\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact_name \u001b[38;5;241m=\u001b[39m act_name\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43msae_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msae_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mact_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mact_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mlp_linearization/src/linearization/analyzer.py:70\u001b[0m, in \u001b[0;36mSAELinearizer.set_model\u001b[0;34m(self, model_name, dataset_name, sae_names, layers, act_name, seed, run_analysis, num_batches, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m     torch\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseed)\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfrequencies \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     65\u001b[0m         name: frequencies(\n\u001b[1;32m     66\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kw1, sae\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msaes[name], layer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msae_layers[name], num_batches\u001b[38;5;241m=\u001b[39mnum_batches\n\u001b[1;32m     67\u001b[0m         )\n\u001b[1;32m     68\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msaes\n\u001b[1;32m     69\u001b[0m     }\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf1_scores \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     71\u001b[0m         name: f1_scores(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kw1, sae\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msaes[name], layer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msae_layers[name], num_batches\u001b[38;5;241m=\u001b[39mnum_batches)\n\u001b[1;32m     72\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msaes\n\u001b[1;32m     73\u001b[0m     }\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# Unset downstream values\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clean(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/mlp_linearization/src/linearization/analyzer.py:71\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     63\u001b[0m     torch\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseed)\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfrequencies \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     65\u001b[0m         name: frequencies(\n\u001b[1;32m     66\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kw1, sae\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msaes[name], layer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msae_layers[name], num_batches\u001b[38;5;241m=\u001b[39mnum_batches\n\u001b[1;32m     67\u001b[0m         )\n\u001b[1;32m     68\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msaes\n\u001b[1;32m     69\u001b[0m     }\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf1_scores \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m---> 71\u001b[0m         name: \u001b[43mf1_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_kw1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msae\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msaes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msae_layers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_batches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_batches\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msaes\n\u001b[1;32m     73\u001b[0m     }\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# Unset downstream values\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clean(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/mlp_linearization/src/linearization/analyses/model.py:86\u001b[0m, in \u001b[0;36mf1_scores\u001b[0;34m(model, sae, data, layer, num_batches, act_name)\u001b[0m\n\u001b[1;32m     83\u001b[0m     activating_tokens \u001b[38;5;241m=\u001b[39m tokens[activating_indices[:, \u001b[38;5;241m0\u001b[39m], activating_indices[:, \u001b[38;5;241m1\u001b[39m]]\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;66;03m# Update feature counters with activating tokens\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m     feature_counters[j]\u001b[38;5;241m.\u001b[39mupdate(\u001b[43mactivating_tokens\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Update token counter with ALL token occurrences\u001b[39;00m\n\u001b[1;32m     89\u001b[0m token_counter\u001b[38;5;241m.\u001b[39mupdate(tokens\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lin = SAELinearizer(model_name=\"gelu-2l\", sae_names=[\"l0\", \"l1\"], layers=[0, 1], act_name=\"mlp_out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:01<00:00, 24.52it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 27.05it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 25.72it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 27.07it/s]\n"
     ]
    }
   ],
   "source": [
    "lin.set_feature(8, \"l1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9])\n",
      "Token:  the\n"
     ]
    }
   ],
   "source": [
    "lin.set_example(\"The quick brown fox jumps over the lazy dog\", 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 8, 11, 11])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin.attributions[\"attn\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT2-small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n",
      "Moving model to device:  cuda\n",
      "Changing model dtype to torch.float16\n",
      "Model device: cuda:0\n",
      "Tokens shape: torch.Size([325017, 128]), dtype: torch.int64, device: cuda:0\n",
      "Loading GPT2-small layer 0 from disk\n",
      "Encoder device: cuda:0\n",
      "Loading GPT2-small layer 1 from disk\n",
      "Encoder device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  8.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num dead 0.206573486328125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  8.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num dead 0.001068115234375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:23<00:00,  4.79s/it]\n",
      "100%|██████████| 5/5 [00:42<00:00,  8.50s/it]\n"
     ]
    }
   ],
   "source": [
    "# This takes like 30 minutes btw, but it's cool...\n",
    "\n",
    "lin = SAELinearizer(model_name=\"gpt2-small\", sae_names=[0, 1], layers=[0, 11], num_batches=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 11.06it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 11.37it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 11.23it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 11.12it/s]\n"
     ]
    }
   ],
   "source": [
    "lin.set_feature(8, 0, num_batches=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20])\n",
      "Token:  the\n"
     ]
    }
   ],
   "source": [
    "lin.set_example(\"The quick brown fox jumps over the lazy dog. The quick brown fox jumps over the lazy dog!!!\", 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 22])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin.attributions[\"ov\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 880x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.matshow(lin.attributions[\"ov\"].detach().cpu().numpy().squeeze())\n",
    "plt.xticks(range(len(lin.example)), [lin.model.tokenizer.decode(x) for x in lin.example], rotation=90)\n",
    "plt.ylabel(\"Layer\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pythia-70M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbf71bf0f04d44b5825e08aa2c415c30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/567 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "695edd2d0918409583f8a3d055eefea1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/166M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6fcc77e998e4769bb683a48d80b8a38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/396 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dee9ad324e17405e9e7f32e8e174eee7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a463bbe3318e4706b7b07d531f7ed521",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model pythia-70m into HookedTransformer\n",
      "Moving model to device:  cuda\n",
      "Changing model dtype to torch.float16\n",
      "Model device: cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "174e6481057744dabbb26c8e06d92c2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=10):   0%|          | 0/20000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens shape: torch.Size([224268, 128]), dtype: torch.int64, device: cuda:0\n",
      "Loading run1 from HuggingFace at 25\n",
      "{'batch_size': 4096,\n",
      " 'beta1': 0.9,\n",
      " 'beta2': 0.99,\n",
      " 'buffer_batches': 12288,\n",
      " 'buffer_mult': 384,\n",
      " 'buffer_size': 1572864,\n",
      " 'd_mlp': 2048,\n",
      " 'dict_mult': 8,\n",
      " 'enc_dtype': 'fp32',\n",
      " 'l1_coeff': 0.0003,\n",
      " 'lr': 0.0001,\n",
      " 'model_batch_size': 512,\n",
      " 'num_tokens': 2000000000,\n",
      " 'seed': 52,\n",
      " 'seq_len': 128}\n",
      "Encoder device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:01<00:00, 20.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num dead 0.04693603515625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:11<00:00,  2.88s/it]\n"
     ]
    }
   ],
   "source": [
    "lin = SAELinearizer(\n",
    "    model_name=\"pythia-70m\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mats",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
